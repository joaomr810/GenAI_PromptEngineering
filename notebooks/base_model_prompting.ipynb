{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt-based Sentiment Classification\n",
    "\n",
    "This notebook demonstrates how to perform sentiment classification using a prompt-based approach with the Meta-Llama text generation model. The workflow includes:\n",
    "- Loading a dataset using pandas.\n",
    "- Generating prompts (both zero-shot and few-shot) from stored Markdown files.\n",
    "- Sending prompts to an API endpoint for text generation.\n",
    "- Parsing and displaying the responses.\n",
    "- Looping over a subset of the data to compare true sentiment labels with predicted classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Training Dataset\n",
    "\n",
    "Adapted from: https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset?resource=download&select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Joao\\Desktop\\ISAG\\2-T\\Generative AI\\Trabalho 1\\materials\\data\\train_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Shape of the Dataset\n",
    "\n",
    "This cell outputs the shape of the training dataframe (number of rows and columns) to quickly verify the dataset's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previewing the Data\n",
    "\n",
    "This cell displays all rows of the training dataset, as it is a small one. It helps in inspecting the structure and content of the data, including columns like `text`, `selected_text`, and `sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0      textID  \\\n",
       "0             0           0  cb774db0d1   \n",
       "1             1           1  549e992a42   \n",
       "2             2           2  088c60f138   \n",
       "3             3           3  9642c003ef   \n",
       "4             4           4  358bd9e861   \n",
       "5             5           5  28b57f3990   \n",
       "6             6           6  6e0c6d75b1   \n",
       "7             7           7  50e14c0bb8   \n",
       "8             8           8  e050245fbd   \n",
       "9             9           9  fc2cbefa9d   \n",
       "\n",
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "                                                                                  selected_text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                                                      Sooo SAD   \n",
       "2                                                                                   bullying me   \n",
       "3                                                                                leave me alone   \n",
       "4                                                                                 Sons of ****,   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                                                                                           fun   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                                                                  Wow... u just became cooler.   \n",
       "\n",
       "  sentiment  \n",
       "0   neutral  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3  negative  \n",
       "4  negative  \n",
       "5   neutral  \n",
       "6  positive  \n",
       "7   neutral  \n",
       "8   neutral  \n",
       "9  positive  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the `chat` Function\n",
    "\n",
    "This cell defines a function named `chat` that sends a prompt to a text generation API using the Meta-Llama model. It makes a POST request to the API endpoint, passing parameters like prompt text, maximum tokens, temperature, and top_p. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERBOLIC_AUTH = \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJqb2FvbXI4MTBAZ21haWwuY29tIiwiaWF0IjoxNzQzNDM4NjMxfQ.obsnhIjgtiQPs0579ZDCZv3dVfhNoZkbQ1S2ZhgG-tM\"\n",
    "MODEL = \"meta-llama/Meta-Llama-3.1-405B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' He was the first to put forward the theory that blue was the color of the sky, and he',\n",
       " {'id': 'cmpl-458de536ac854b64a42f90a4e2838365',\n",
       "  'choices': [{'finish_reason': 'length',\n",
       "    'index': 0,\n",
       "    'logprobs': None,\n",
       "    'text': ' He was the first to put forward the theory that blue was the color of the sky, and he'}],\n",
       "  'created': 1743461421,\n",
       "  'model': 'meta-llama/Meta-Llama-3.1-405B',\n",
       "  'system_fingerprint': '',\n",
       "  'object': 'text_completion',\n",
       "  'usage': {'prompt_tokens': 2, 'total_tokens': 22, 'completion_tokens': 20}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def retry(times, exceptions):\n",
    "    \"\"\"\n",
    "    Retry Decorator\n",
    "    Retries the wrapped function/method `times` times if the exceptions listed\n",
    "    in ``exceptions`` are thrown\n",
    "    :param times: The number of times to repeat the wrapped function/method\n",
    "    :type times: Int\n",
    "    :param Exceptions: Lists of exceptions that trigger a retry attempt\n",
    "    :type Exceptions: Tuple of Exceptions\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        def newfn(*args, **kwargs):\n",
    "            attempt = 0\n",
    "            while attempt < times:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except exceptions as e:\n",
    "                    print(\n",
    "                        'Exception %s thrown when attempting to run %s, attempt '\n",
    "                        '%d of %d. We\\'ll wait 20seconds.' % (e, func, attempt, times)\n",
    "                    )\n",
    "                    attempt += 1\n",
    "                    time.sleep(20)\n",
    "            return func(*args, **kwargs)\n",
    "        return newfn\n",
    "    return decorator\n",
    "\n",
    "class TooManyRequests(Exception):\n",
    "    pass\n",
    "\n",
    "@retry(times=3, exceptions=(TooManyRequests,))\n",
    "def chat(prompt: str, max_tokens: int=2) -> str:\n",
    "    url = \"https://api.hyperbolic.xyz/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": HYPERBOLIC_AUTH\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": MODEL,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code==200:\n",
    "        return response.json()[\"choices\"][0][\"text\"], response.json()\n",
    "    elif response.status_code==429:\n",
    "        raise TooManyRequests(response.text)\n",
    "    else:\n",
    "        return None, response.json()\n",
    "\n",
    "message, response = chat(\"say blue.\", max_tokens=20)\n",
    "message, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the `get_prompt` Function\n",
    "\n",
    "This cell defines a helper function `get_prompt` that reads a Markdown file (located in the `../../prompts/` directory) corresponding to a system prompt. It then formats the prompt by inserting the provided user text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório atual: c:\\Users\\Joao\\Desktop\\ISAG\\2-T\\Generative AI\\Trabalho 1\\materials\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Diretório atual:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(system_prompt_name: str, user_prompt) -> str:\n",
    "    base_path = os.path.join(\"..\", \"prompts\")\n",
    "    path = os.path.join(base_path, system_prompt_name + \".md\")\n",
    "    with open(path, 'r') as f:\n",
    "        markdown_string = f.read()\n",
    "    return markdown_string.format(user_prompt=user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and Displaying a Zero-shot Prompt\n",
    "\n",
    "This cell generates a zero-shot prompt for sentiment classification using the example text \"hello friend!\" by calling the get_prompt function with the \"zero_shot\" prompt template. The generated prompt is then displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Classify the text into neutral, negative or positive.\n",
       "\n",
       "Text: hello friend!\n",
       "Sentiment: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_shot_prompt = get_prompt(system_prompt_name=\"zero_shot_base\", user_prompt=\"hello friend!\")\n",
    "display(Markdown(zero_shot_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Zero-shot Prompt via the API\n",
    "This cell sends the generated zero-shot prompt to the chat function with a max_tokens limit of 2, and displays the API response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1\\n',\n",
       " {'id': 'cmpl-b64bb4dfb8594937ad36ed02bd1d3853',\n",
       "  'choices': [{'finish_reason': 'length',\n",
       "    'index': 0,\n",
       "    'logprobs': None,\n",
       "    'text': '1\\n'}],\n",
       "  'created': 1743461709,\n",
       "  'model': 'meta-llama/Meta-Llama-3.1-405B',\n",
       "  'system_fingerprint': '',\n",
       "  'object': 'text_completion',\n",
       "  'usage': {'prompt_tokens': 2, 'total_tokens': 4, 'completion_tokens': 2}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(zero_shot_prompt, max_tokens=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Few-shot Prompt\n",
    "\n",
    "**Exercise 1**: you need to use a system prompt using \"few shot\" technique. Make sure to not use data available on test.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
